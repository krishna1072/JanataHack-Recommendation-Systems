{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "NN_Recommendation_Systems.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishna1072/JanataHack-Recommendation-Systems/blob/master/NN_Recommendation_Systems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqdcYyp4dYyB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import gensim\n",
        "from random import sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZ3f7LHsdYyG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load train data\n",
        "zf = zipfile.ZipFile('/content/train_mddNHeX.zip') # having First.csv zipped file.\n",
        "train_chal = pd.read_csv(zf.open('train.csv'))\n",
        "display(train_chal.head())\n",
        "train_chal.info()\n",
        "\n",
        "# Load all the challenges\n",
        "challenges = pd.read_csv(zf.open('challenge_data.csv'))\n",
        "challenges['publish_date'] = pd.to_datetime(challenges['publish_date'])\n",
        "display(challenges.head())\n",
        "challenges.info()\n",
        "\n",
        "# Load test data\n",
        "zf = zipfile.ZipFile('/content/test_HLxMpl7.zip') # having First.csv zipped file.\n",
        "test_chal = pd.read_csv(zf.open('test.csv'))\n",
        "display(test_chal.head())\n",
        "test_chal.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kePoBfiadYyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=train_chal.groupby('user_id').challenge.apply(lambda x: ' '.join(x)).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY3OHEcAdYyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test=test_chal.groupby('user_id').challenge.apply(lambda x: ' '.join(x)).reset_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRhahPnrdYyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "set(train.user_id).intersection(test.user_id)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vH9EwIl_dYyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.shape, test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4j9JWFDdYyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence_list=pd.concat((train.challenge,test.challenge)).apply(lambda x: x.split())\n",
        "# sentence_list= train.challenge.apply(lambda x: x.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLAdUs58dYyh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train word2vec model to learn embeddings\n",
        "neg=15\n",
        "itera=100\n",
        "window=5\n",
        "size=500\n",
        "print ('doing_'+str(neg)+'_'+str(window)+'_'+str(itera))\n",
        "model=gensim.models.Word2Vec(sentence_list,size=size,window=window,workers=8,min_count=0, hs=1,iter=itera,sg=1)\n",
        "model.save('word2vec_solved_iter__noshuf_5window_'+ str(itera) + '_size_' + str(size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOQarZf-dYyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model= gensim.models.Word2Vec.load('word2vec_solved_iter__noshuf_5window_100_size_500')\n",
        "model.most_similar('CI23855')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2l7fdDPdYyp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout, Activation\n",
        "from keras.layers import TimeDistributed, concatenate, Bidirectional, Masking, RepeatVector #,Merge\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers.recurrent import LSTM, GRU, SimpleRNN\n",
        "from keras.layers.convolutional import Convolution1D, MaxPooling1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_VCcQu6dYyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_weights = model.wv.syn0\n",
        "vocab_size, emdedding_size = pretrained_weights.shape\n",
        "print('Result embedding shape:', pretrained_weights.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pgF1Pr-dYyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def word2idx(word):\n",
        "    return model.wv.vocab[word].index\n",
        "def idx2word(idx):\n",
        "    return model.wv.index2word[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KI1Q2MqdYy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generate int sequences for challenge sentences\n",
        "train_seq=np.array(train.challenge.apply(lambda x: x.split()).apply(lambda x: ([(word2idx(y)) for y in x])).tolist())\n",
        "test_seq=np.array(test.challenge.apply(lambda x: x.split()).apply(lambda x: ([(word2idx(y)) for y in x])).tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7-Xy2MhdYy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xtrain=train_seq[:,:10]\n",
        "ytrain= train_seq[:,10]\n",
        "xtrain.shape, ytrain.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qjd7ktdDdYzA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add 11th,12th,13th challenge to outcome\n",
        "xtrain= np.concatenate((xtrain,xtrain,xtrain),axis=0)\n",
        "ytrain= np.concatenate((train_seq[:,10],train_seq[:,11],train_seq[:,12]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfgD-StNdYzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define nn model\n",
        "emdedding_size=500\n",
        "vocab_size=5502\n",
        "keras_model2 = Sequential()\n",
        "keras_model2.add(Embedding(input_dim=vocab_size, output_dim=emdedding_size, \n",
        "                    weights=[pretrained_weights]))\n",
        "keras_model2.add(GRU(units=emdedding_size))\n",
        "keras_model2.add(Dense(units=vocab_size))\n",
        "\n",
        "keras_model2.add(Activation('softmax'))\n",
        "keras_model2.compile(optimizer='adam', loss='sparse_categorical_crossentropy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xq3yAENSdYzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_weight=np.concatenate((np.ones(train.shape[0])*3,np.ones(train.shape[0])*2,np.ones(train.shape[0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "h3f1YrGHdYzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit differnt samples of data and then full data\n",
        "keras_model2.fit(xtrain,ytrain, epochs=2, sample_weight=sample_weight,\n",
        "          batch_size=512, verbose=1,validation_split=0.11)\n",
        "keras_model2.fit(xtrain,ytrain, epochs=1, sample_weight=sample_weight,\n",
        "          batch_size=512, verbose=1,validation_split=0.11)\n",
        "keras_model2.fit(xtrain,ytrain, epochs=1, sample_weight=sample_weight,\n",
        "          batch_size=512, verbose=1,validation_split=0.11)\n",
        "keras_model2.fit(xtrain,ytrain, epochs=1, sample_weight=sample_weight,\n",
        "          batch_size=512, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkc0mr5fdYzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dump(keras_model2.to_json(),open('gru4.pkl','wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOHR8fJadYzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import keras\n",
        "# from importlib import reload\n",
        "# import keras\n",
        "keras_model2.save_weights('gru4.weights')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a78jaipedYzY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    if temperature <= 0:\n",
        "        return preds.argsort()[-3:][::-1]\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "#     print max(probas[0])\n",
        "    retar= probas[0].argsort()[-3:][::-1]\n",
        "    return retar\n",
        "\n",
        "def generate_next(text):\n",
        "    # global count\n",
        "    # count+=1\n",
        "    # if count%100==0:\n",
        "    #     print (count)\n",
        "    word_idxs = [word2idx(word) for word in text.split()]\n",
        "    prediction = keras_model2.predict(x=np.array(word_idxs))\n",
        "#     print prediction\n",
        "    idxl = sample(prediction[-1], temperature=0.0)\n",
        "#     word_idxs.e(idx)\n",
        "#     print idxl\n",
        "    return [idx2word(idx) for idx in idxl]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJyyhV5NdYzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test.challenge.values[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vacpDXZUdYzf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generate_next('CI23855 CI23933 CI24917 CI24915 CI23714 CI23663 CI24958 CI25135 CI25727 CI24530')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwFMY3fWdYzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_inds=np.array(test.challenge.apply(lambda x: np.array([word2idx(word) for word in x.split()])).tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zZhODXKdYzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_inds.shape, xtrain.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJdEI8eZdYzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make predictions\n",
        "nnpred=keras_model2.predict(test_inds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zf7FrVQ0dYzv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnpred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Tvyn0D4dYzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nnpred2= pd.Series(nnpred.argsort(axis=1)[:,-3:].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ne_3AH4rdYz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# store to csv\n",
        "count=0\n",
        "test['pred']=nnpred2.apply(lambda x: [idx2word(y) for y in x[::-1]])\n",
        "test_sub= test.copy()\n",
        "test_sub=pd.concat((test_sub,test_sub,test_sub))\n",
        "test_sub=test_sub.sort_values('user_id').reset_index(drop=True)\n",
        "test_sub['seq']=test_sub.groupby('user_id').cumcount()\n",
        "test_sub.seq= test_sub.seq+11\n",
        "test_sub['user_sequence']= test_sub.user_id.astype('str') + '_' + test_sub.seq.astype('str')\n",
        "test_sub['challenge']=test_sub.apply(lambda row: row['pred'][row['seq']-11], axis=1)\n",
        "test_sub[['user_sequence','challenge']].to_csv('/content/NN_submission_06282020.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}